{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6031bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import NamedTuple\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from jax import block_until_ready, grad, jit, lax, random, vmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b808e4",
   "metadata": {},
   "source": [
    "# jax_pso.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaxSwarmState(NamedTuple):\n",
    "    positions: jnp.ndarray\n",
    "    velocities: jnp.ndarray\n",
    "    p_best_pos: jnp.ndarray\n",
    "    p_best_fit: jnp.ndarray\n",
    "    g_best_pos: jnp.ndarray\n",
    "    g_best_fit: jnp.ndarray\n",
    "    rng: random.PRNGKey\n",
    "\n",
    "class GradientState(NamedTuple):\n",
    "    new_g_best_pos: jnp.ndarray\n",
    "    lower: jnp.ndarray\n",
    "    upper: jnp.ndarray\n",
    "    eta: float\n",
    "\n",
    "@partial(\n",
    "    jit,\n",
    "    static_argnames=(\n",
    "        \"objective_fn\",\n",
    "        \"bounds\",\n",
    "        \"num_dims\",\n",
    "        \"num_particles\",\n",
    "        \"max_iters\",\n",
    "        \"c1\",\n",
    "        \"c2\",\n",
    "        \"w\",\n",
    "        \"eta\",\n",
    "        \"steps\",\n",
    "    ),\n",
    ")\n",
    "def jax_gd_pso(\n",
    "    objective_fn: callable,\n",
    "    bounds: tuple,\n",
    "    num_dims: int,\n",
    "    num_particles: int,\n",
    "    max_iters: int,\n",
    "    c1: float,\n",
    "    c2: float,\n",
    "    w: float,\n",
    "    seed: random.PRNGKey,\n",
    "    eta: float,\n",
    "    steps: int,\n",
    ") -> tuple:\n",
    "    key = seed\n",
    "    lower, upper = bounds\n",
    "    k_pos, k_vel, k_state = random.split(key, 3)\n",
    "\n",
    "    search_range = upper - lower\n",
    "    velocity_scale = 0.1\n",
    "    limit = search_range * velocity_scale\n",
    "\n",
    "    init_positions = random.uniform(\n",
    "        k_pos, (num_particles, num_dims), minval=lower, maxval=upper,\n",
    "    )\n",
    "    init_velocities = random.uniform(\n",
    "        k_vel, (num_particles, num_dims), minval=-limit, maxval=limit,\n",
    "    )\n",
    "    init_fitness = vmap(objective_fn)(init_positions)\n",
    "\n",
    "    best_idx = jnp.argmin(init_fitness)\n",
    "    g_best_pos = init_positions[best_idx]\n",
    "    g_best_fit = init_fitness[best_idx]\n",
    "\n",
    "    initial_state = JaxSwarmState(\n",
    "        positions=init_positions,\n",
    "        velocities=init_velocities,\n",
    "        p_best_pos=init_positions,\n",
    "        p_best_fit=init_fitness,\n",
    "        g_best_pos=g_best_pos,\n",
    "        g_best_fit=g_best_fit,\n",
    "        rng=k_state,\n",
    "    )\n",
    "\n",
    "    gradient_fn = grad(objective_fn)\n",
    "\n",
    "    def update_step(swarm_state: JaxSwarmState, i: int) -> tuple:\n",
    "        k1, k2, k_next = random.split(swarm_state.rng, 3)\n",
    "        r1 = random.uniform(k1, (num_particles, num_dims))\n",
    "        r2 = random.uniform(k2, (num_particles, num_dims))\n",
    "\n",
    "        inertia = w * swarm_state.velocities\n",
    "        cognitive = c1 * r1 * (swarm_state.p_best_pos - swarm_state.positions)\n",
    "        social = c2 * r2 * (swarm_state.g_best_pos - swarm_state.positions)\n",
    "\n",
    "        new_velocities = inertia + cognitive + social\n",
    "        new_positions = swarm_state.positions + new_velocities\n",
    "        new_positions = jnp.clip(new_positions, lower, upper)\n",
    "\n",
    "        new_fitness = vmap(objective_fn)(new_positions)\n",
    "\n",
    "        improved = new_fitness < swarm_state.p_best_fit\n",
    "        mask = improved[:, None]\n",
    "        new_p_best_pos = jnp.where(mask, new_positions, swarm_state.p_best_pos)\n",
    "        new_p_best_fit = jnp.where(improved, new_fitness, swarm_state.p_best_fit)\n",
    "\n",
    "        current_g_best_idx = jnp.argmin(new_p_best_fit)\n",
    "        current_g_best_fit = new_p_best_fit[current_g_best_idx]\n",
    "\n",
    "        global_improved = current_g_best_fit < swarm_state.g_best_fit\n",
    "        candidate_g_pos = jnp.where(\n",
    "            global_improved, new_p_best_pos[current_g_best_idx], swarm_state.g_best_pos,\n",
    "        )\n",
    "        candidate_g_fit = jnp.where(\n",
    "            global_improved, current_g_best_fit, swarm_state.g_best_fit,\n",
    "        )\n",
    "\n",
    "        def gradient_descent_step(g_state: GradientState, _: None) -> tuple:\n",
    "            grads = gradient_fn(g_state.new_g_best_pos)\n",
    "            step = g_state.eta * grads\n",
    "            updated_pos = g_state.new_g_best_pos - step\n",
    "            updated_pos = jnp.clip(updated_pos, g_state.lower, g_state.upper)\n",
    "            next_state = GradientState(\n",
    "                new_g_best_pos=updated_pos,\n",
    "                lower=g_state.lower,\n",
    "                upper=g_state.upper,\n",
    "                eta=g_state.eta,\n",
    "            )\n",
    "            return next_state, None\n",
    "\n",
    "        def apply_gradient(_: None) -> tuple:\n",
    "            init_grad_state = GradientState(candidate_g_pos, lower, upper, eta)\n",
    "            final_grad_state, _ = lax.scan(\n",
    "                gradient_descent_step,\n",
    "                init_grad_state,\n",
    "                None,\n",
    "                steps,\n",
    "            )\n",
    "            final_pos = final_grad_state.new_g_best_pos\n",
    "            return final_pos, objective_fn(final_pos)\n",
    "\n",
    "        def skip_gradient(_: None) -> tuple:\n",
    "            return candidate_g_pos, candidate_g_fit\n",
    "\n",
    "        gradient_g_pos, gradient_g_fit = lax.cond(\n",
    "            i % 10 == 0,\n",
    "            apply_gradient,\n",
    "            skip_gradient,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "        global_improved = gradient_g_fit < candidate_g_fit\n",
    "        final_g_pos = jnp.where(global_improved, gradient_g_pos, candidate_g_pos)\n",
    "        final_g_fit = jnp.where(global_improved, gradient_g_fit, candidate_g_fit)\n",
    "\n",
    "        next_state = JaxSwarmState(\n",
    "            positions=new_positions,\n",
    "            velocities=new_velocities,\n",
    "            p_best_pos=new_p_best_pos,\n",
    "            p_best_fit=new_p_best_fit,\n",
    "            g_best_pos=final_g_pos,\n",
    "            g_best_fit=final_g_fit,\n",
    "            rng=k_next,\n",
    "        )\n",
    "\n",
    "        return next_state, final_g_fit\n",
    "\n",
    "    final_state, history = lax.scan(update_step, initial_state, jnp.arange(max_iters))\n",
    "    full_history = jnp.concatenate([jnp.array([initial_state.g_best_fit]), history])\n",
    "\n",
    "    return final_state.g_best_pos, final_state.g_best_fit, full_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7356ef",
   "metadata": {},
   "source": [
    "# numpy_pso.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwarmState(NamedTuple):\n",
    "    positions: np.ndarray\n",
    "    velocities: np.ndarray\n",
    "    p_best_pos: np.ndarray\n",
    "    p_best_fit: np.ndarray\n",
    "    g_best_pos: np.ndarray\n",
    "    g_best_fit: np.ndarray\n",
    "    rng: np.random.Generator\n",
    "    history: np.ndarray\n",
    "\n",
    "def numpy_pso(\n",
    "    objective_fn: callable,\n",
    "    bounds: tuple,\n",
    "    num_dims: int,\n",
    "    num_particles: int,\n",
    "    max_iters: int,\n",
    "    c1: float,\n",
    "    c2: float,\n",
    "    w: float,\n",
    "    seed: int,\n",
    "    **_: any,\n",
    ") -> tuple:\n",
    "    lower, upper = bounds\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    init_positions = rng.uniform(lower, upper, (num_particles, num_dims))\n",
    "    init_velocities = np.zeros((num_particles, num_dims))\n",
    "    init_fitness = np.array([objective_fn(position) for position in init_positions])\n",
    "\n",
    "    best_idx = np.argmin(init_fitness)\n",
    "    g_best_pos = init_positions[best_idx]\n",
    "    g_best_fit = init_fitness[best_idx]\n",
    "\n",
    "    history = np.zeros(max_iters)\n",
    "    history[0] = g_best_fit\n",
    "\n",
    "    swarm_state = SwarmState(\n",
    "        positions=init_positions,\n",
    "        velocities=init_velocities,\n",
    "        p_best_pos=init_positions,\n",
    "        p_best_fit=init_fitness,\n",
    "        g_best_pos=g_best_pos,\n",
    "        g_best_fit=g_best_fit,\n",
    "        rng=rng,\n",
    "        history=history,\n",
    "    )\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        r1 = swarm_state.rng.random((num_particles, num_dims))\n",
    "        r2 = swarm_state.rng.random((num_particles, num_dims))\n",
    "\n",
    "        inertia = w * swarm_state.velocities\n",
    "        cognitive = c1 * r1 * (swarm_state.p_best_pos - swarm_state.positions)\n",
    "        social = c2 * r2 * (swarm_state.g_best_pos - swarm_state.positions)\n",
    "\n",
    "        new_velocities = inertia + cognitive + social\n",
    "        new_positions = swarm_state.positions + new_velocities\n",
    "        new_positions = np.clip(new_positions, lower, upper)\n",
    "\n",
    "        new_fitness = np.array([objective_fn(pos) for pos in new_positions])\n",
    "\n",
    "        improved = new_fitness < swarm_state.p_best_fit\n",
    "        mask = improved[:, None]\n",
    "        new_p_best_pos = np.where(mask, new_positions, swarm_state.p_best_pos)\n",
    "        new_p_best_fit = np.where(improved, new_fitness, swarm_state.p_best_fit)\n",
    "\n",
    "        current_g_best_idx = np.argmin(new_p_best_fit)\n",
    "        current_g_best_fit = new_p_best_fit[current_g_best_idx]\n",
    "        global_improved = current_g_best_fit < swarm_state.g_best_fit\n",
    "        new_g_best_pos = np.where(\n",
    "            global_improved, new_p_best_pos[current_g_best_idx], swarm_state.g_best_pos,\n",
    "        )\n",
    "        new_g_best_fit = np.where(\n",
    "            global_improved, current_g_best_fit, swarm_state.g_best_fit,\n",
    "        )\n",
    "\n",
    "        new_history = swarm_state.history\n",
    "        new_history[i] = new_g_best_fit\n",
    "\n",
    "        swarm_state = SwarmState(\n",
    "            positions=new_positions,\n",
    "            velocities=new_velocities,\n",
    "            p_best_pos=new_p_best_pos,\n",
    "            p_best_fit=new_p_best_fit,\n",
    "            g_best_pos=new_g_best_pos,\n",
    "            g_best_fit=new_g_best_fit,\n",
    "            rng=swarm_state.rng,\n",
    "            history=new_history,\n",
    "        )\n",
    "\n",
    "    return swarm_state.g_best_pos, swarm_state.g_best_fit, swarm_state.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33198d1",
   "metadata": {},
   "source": [
    "# plot_benchmarks.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e98c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_figure(fig: plt.Figure, filename: str, config: dict) -> None:\n",
    "    save_path = config[\"output_path\"] / filename\n",
    "    fig.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_execution_time_dims(df: pd.DataFrame, config: dict) -> None:\n",
    "    benchmarks = df[\"Benchmark\"].unique()\n",
    "    fig, axes = plt.subplots(\n",
    "        4,\n",
    "        4,\n",
    "        figsize=(7, 7),\n",
    "        constrained_layout=True,\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "    )\n",
    "    axes_flat = axes.flatten()\n",
    "\n",
    "    for ax, benchmark in zip(axes_flat, benchmarks, strict=True):\n",
    "        df_benchmark = df[df[\"Benchmark\"] == benchmark]\n",
    "        algorithms = df_benchmark[\"Algorithm\"].unique()\n",
    "        colors = sns.color_palette(n_colors=len(algorithms))\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=df_benchmark,\n",
    "            x=\"Dimension\",\n",
    "            y=\"Mean of Execution Times (s)\",\n",
    "            hue=\"Algorithm\",\n",
    "            marker=\"o\",\n",
    "            palette=config[\"palette\"],\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        for algorithm, color in zip(algorithms, colors, strict=True):\n",
    "            data_algorithm = df_benchmark[df_benchmark[\"Algorithm\"] == algorithm]\n",
    "            mean = data_algorithm[\"Mean of Execution Times (s)\"]\n",
    "            std = data_algorithm[\"Standard Deviation of Execution Times (s)\"]\n",
    "\n",
    "            ax.fill_between(\n",
    "                data_algorithm[\"Dimension\"],\n",
    "                mean - std,\n",
    "                mean + std,\n",
    "                color=color,\n",
    "                alpha=0.2,\n",
    "            )\n",
    "\n",
    "        ax.set_title(f\"{benchmark}\", fontweight=\"bold\")\n",
    "        ax.set(xlabel=\"\", ylabel=\"\", yscale=\"log\")\n",
    "        ax.get_legend().remove()\n",
    "\n",
    "    fig.supxlabel(\"Dimension\", fontsize=8)\n",
    "    fig.supylabel(\"Mean of Execution Times (s)\", fontsize=8)\n",
    "\n",
    "    handles, labels = axes_flat[0].get_legend_handles_labels()\n",
    "    fig.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 1.05),\n",
    "        ncol=3,\n",
    "        frameon=False,\n",
    "    )\n",
    "\n",
    "    _save_figure(fig, \"execution_time_dims.pdf\", config)\n",
    "\n",
    "def plot_convergence(df: pd.DataFrame, config: dict) -> None:\n",
    "    benchmarks = df[\"Benchmark\"].unique()\n",
    "    dimensions = df[\"Dimension\"].unique()\n",
    "\n",
    "    for benchmark in benchmarks:\n",
    "        for dimension in dimensions:\n",
    "            df_subset = df[\n",
    "                (df[\"Dimension\"] == dimension) & (df[\"Benchmark\"] == benchmark)\n",
    "            ]\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "            for _, row in df_subset.iterrows():\n",
    "                sns.lineplot(\n",
    "                    data=row[\"Fitness History\"],\n",
    "                    ax=ax,\n",
    "                    label=row[\"Algorithm\"],\n",
    "                )\n",
    "\n",
    "            ax.set(xlabel=\"Iteration\", ylabel=\"Fitness\")\n",
    "            ax.set_title(\"Convergence History\", fontweight=\"bold\")\n",
    "            ax.legend(title=\"Algorithms\")\n",
    "            _save_figure(fig, f\"convergence_{benchmark}_{dimension}d.pdf\", config)\n",
    "\n",
    "def generate_summary_tables(df: pd.DataFrame, config: dict) -> None:\n",
    "    for dim, df_dim in df.groupby(\"Dimension\"):\n",
    "        pivot_table = df_dim.pivot_table(\n",
    "            index=\"Benchmark\",\n",
    "            columns=\"Algorithm\",\n",
    "            values =\"Mean of Execution Times (s)\",\n",
    "        )\n",
    "        save_path = config[\"output_path\"] / f\"execution_time_table_{dim}d.csv\"\n",
    "        pivot_table.to_csv(save_path)\n",
    "\n",
    "def generate_visualizations(df: pd.DataFrame) -> None:\n",
    "    config = {\n",
    "        \"output_path\": Path(\"./results/\"),\n",
    "        \"palette\": \"viridis\",\n",
    "        \"font\": {\n",
    "            \"font.size\": 7,\n",
    "            \"axes.titlesize\": 9,\n",
    "            \"legend.fontsize\": 8,\n",
    "            \"axes.labelsize\": 10,\n",
    "            \"xtick.labelsize\": 7.5,\n",
    "            \"ytick.labelsize\": 7.5,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    print(\"Plotting execution time by dimensions...\")\n",
    "    plot_execution_time_dims(df, config)\n",
    "\n",
    "    print(\"Generating summary tables...\")\n",
    "    generate_summary_tables(df, config)\n",
    "\n",
    "    print(\"Plotting convergence histories...\")\n",
    "    plot_convergence(df, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6573d381",
   "metadata": {},
   "source": [
    "# benchmarks.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5015030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ackley_py(x: list) -> float:\n",
    "    n = len(x)\n",
    "    sum1 = sum(xi**2 for xi in x)\n",
    "    sum2 = sum(math.cos(2 * math.pi * xi) for xi in x)\n",
    "    return -20 * math.exp(-0.2 * math.sqrt(sum1 / n)) - math.exp(sum2 / n) + 20 + math.e\n",
    "\n",
    "def rastrigin_py(x: list) -> float:\n",
    "    n = len(x)\n",
    "    return 10 * n + sum(xi**2 - 10 * math.cos(2 * math.pi * xi) for xi in x)\n",
    "\n",
    "def sphere_py(x: list) -> float:\n",
    "    return sum(xi**2 for xi in x)\n",
    "\n",
    "def rosenbrock_py(x: list) -> float:\n",
    "    return sum(100 * (x[i+1] - x[i]**2)**2 + (x[i] - 1)**2 for i in range(len(x) - 1))\n",
    "\n",
    "def ackley_np(x: np.ndarray) -> float:\n",
    "    n = x.shape[0]\n",
    "    sum1 = np.sum(x**2)\n",
    "    sum2 = np.sum(np.cos(2 * np.pi * x))\n",
    "    return -20 * np.exp(-0.2 * np.sqrt(sum1 / n)) - np.exp(sum2 / n) + 20 + np.e\n",
    "\n",
    "def rastrigin_np(x: np.ndarray) -> float:\n",
    "    n = x.shape[0]\n",
    "    return 10 * n + np.sum(x**2 - 10 * np.cos(2 * np.pi * x))\n",
    "\n",
    "def sphere_np(x: np.ndarray) -> float:\n",
    "    return np.sum(x**2)\n",
    "\n",
    "def rosenbrock_np(x: np.ndarray) -> float:\n",
    "    return np.sum(100 * (x[1:] - x[:-1]**2)**2 + (1 - x[:-1])**2)\n",
    "\n",
    "@jit\n",
    "def ackley_jax(x: jnp.ndarray) -> jnp.ndarray:\n",
    "    n = x.shape[0]\n",
    "    sum1 = jnp.sum(x**2)\n",
    "    sum2 = jnp.sum(jnp.cos(2 * jnp.pi * x))\n",
    "    return -20 * jnp.exp(-0.2 * jnp.sqrt(sum1 / n)) - jnp.exp(sum2 / n) + 20 + jnp.e\n",
    "\n",
    "@jit\n",
    "def rastrigin_jax(x: jnp.ndarray) -> jnp.ndarray:\n",
    "    n = x.shape[0]\n",
    "    return 10 * n + jnp.sum(x**2 - 10 * jnp.cos(2 * jnp.pi * x))\n",
    "\n",
    "@jit\n",
    "def sphere_jax(x: jnp.ndarray) -> jnp.ndarray:\n",
    "    return jnp.sum(x**2)\n",
    "\n",
    "@jit\n",
    "def rosenbrock_jax(x: jnp.ndarray) -> jnp.ndarray:\n",
    "    return jnp.sum(100 * (x[1:] - x[:-1]**2)**2 + (1 - x[:-1])**2)\n",
    "\n",
    "BENCHMARKS = {\n",
    "    \"Ackley\": {\n",
    "        \"bounds\": (-32.768, 32.768),\n",
    "        \"Python PSO\": ackley_py,\n",
    "        \"NumPy PSO\": ackley_np,\n",
    "        \"JAX PSO\": ackley_jax,\n",
    "    },\n",
    "    \"Rastrigin\": {\n",
    "        \"bounds\": (-5.12, 5.12),\n",
    "        \"Python PSO\": rastrigin_py,\n",
    "        \"NumPy PSO\": rastrigin_np,\n",
    "        \"JAX PSO\": rastrigin_jax,\n",
    "    },\n",
    "    \"Rosenbrock\": {\n",
    "        \"bounds\": (-5.0, 10.0),\n",
    "        \"Python PSO\": rosenbrock_py,\n",
    "        \"NumPy PSO\": rosenbrock_np,\n",
    "        \"JAX PSO\": rosenbrock_jax,\n",
    "    },\n",
    "    \"Sphere\": {\n",
    "        \"bounds\": (-5.12, 5.12),\n",
    "        \"Python PSO\": sphere_py,\n",
    "        \"NumPy PSO\": sphere_np,\n",
    "        \"JAX PSO\": sphere_jax,\n",
    "    },\n",
    "}\n",
    "\n",
    "ALGORITHMS = {\n",
    "    \"NumPy PSO\": numpy_pso,\n",
    "    \"JAX PSO\": jax_gd_pso,\n",
    "}\n",
    "\n",
    "DIMS = [10, 30, 50, 100]\n",
    "\n",
    "HYPERPARAMETERS = {\n",
    "    \"num_dims\": None,\n",
    "    \"num_particles\": 30,\n",
    "    \"max_iters\": 100,\n",
    "    \"c1\": 1.5,\n",
    "    \"c2\": 1.5,\n",
    "    \"w\": 0.7,\n",
    "    \"seed\": None,\n",
    "    \"eta\": 0.001,\n",
    "    \"steps\": 5,\n",
    "}\n",
    "\n",
    "NUM_RUNS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90b675",
   "metadata": {},
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment() -> list[dict]:\n",
    "    results = []\n",
    "\n",
    "    total_configs = len(DIMS) * len(ALGORITHMS) * len(BENCHMARKS)\n",
    "    current_config = 0\n",
    "\n",
    "    for dim in DIMS:\n",
    "        print(f\"Dimension: {dim}\")\n",
    "        for algorithm_name, algorithm_fn in ALGORITHMS.items():\n",
    "            for benchmark_name, benchmark_config in BENCHMARKS.items():\n",
    "                current_config += 1\n",
    "\n",
    "                objective_fn = benchmark_config[algorithm_name]\n",
    "                bounds = benchmark_config[\"bounds\"]\n",
    "                hyperparameters = HYPERPARAMETERS.copy()\n",
    "                hyperparameters[\"num_dims\"] = dim\n",
    "\n",
    "                print(\n",
    "                    f\"[{current_config}/{total_configs}] Running {algorithm_name} \"\n",
    "                    f\"on {benchmark_name}\",\n",
    "                )\n",
    "\n",
    "                execution_times = []\n",
    "                fitness_history = []\n",
    "                for i in range(NUM_RUNS):\n",
    "                    hyperparameters[\"seed\"] = i\n",
    "\n",
    "                    if algorithm_name == \"JAX PSO\":\n",
    "                        hyperparameters[\"seed\"] = random.PRNGKey(i)\n",
    "\n",
    "                    start = time.perf_counter()\n",
    "                    result = algorithm_fn(objective_fn, bounds, **hyperparameters)\n",
    "\n",
    "                    if algorithm_name == \"JAX PSO\":\n",
    "                        block_until_ready(result)\n",
    "\n",
    "                    end = time.perf_counter()\n",
    "                    execution_times.append(end - start)\n",
    "\n",
    "                    _, fitness, _ = result\n",
    "\n",
    "                    print(f\"Iteration {i + 1} | Fitness: {fitness}\")\n",
    "                    fitness_history.append(fitness)\n",
    "\n",
    "                mean_time = float(jnp.mean(jnp.array(execution_times)))\n",
    "                std_time = float(jnp.std(jnp.array(execution_times)))\n",
    "\n",
    "                mean_fitness = float(jnp.mean(jnp.array(fitness_history)))\n",
    "                std_fitness = float(jnp.std(jnp.array(fitness_history)))\n",
    "\n",
    "\n",
    "                results.extend(\n",
    "                        [\n",
    "                            {\n",
    "                                \"Dimension\": dim,\n",
    "                                \"Benchmark\": benchmark_name,\n",
    "                                \"Algorithm\": algorithm_name,\n",
    "                                \"Execution Time History\": execution_times,\n",
    "                                \"Mean of Execution Times (s)\": mean_time,\n",
    "                                \"Standard Deviation of Execution Times (s)\": std_time,\n",
    "                                \"Fitness History\": fitness_history,\n",
    "                                \"Mean of Fitness\": mean_fitness,\n",
    "                                \"Standard Deviation of Fitness\": std_fitness,\n",
    "                            },\n",
    "                        ],\n",
    "                    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_experiment()\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce57a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./experiment_results.csv\")\n",
    "generate_visualizations(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
