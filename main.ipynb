{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6031bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import NamedTuple\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from jax import block_until_ready, grad, jit, lax, random, vmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b808e4",
   "metadata": {},
   "source": [
    "# jax_gd_pso.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaxGdSwarmState(NamedTuple):\n",
    "    positions: jnp.ndarray\n",
    "    velocities: jnp.ndarray\n",
    "    p_best_pos: jnp.ndarray\n",
    "    p_best_fit: jnp.ndarray\n",
    "    g_best_pos: jnp.ndarray\n",
    "    g_best_fit: jnp.ndarray\n",
    "    rng: random.PRNGKey\n",
    "\n",
    "\n",
    "class GradientState(NamedTuple):\n",
    "    current_pos: jnp.ndarray\n",
    "\n",
    "\n",
    "@partial(\n",
    "    jit,\n",
    "    static_argnames=(\n",
    "        \"objective_fn\",\n",
    "        \"num_dims\",\n",
    "        \"num_particles\",\n",
    "        \"max_iters\",\n",
    "        \"steps\",\n",
    "    ),\n",
    ")\n",
    "def jax_gd_pso(\n",
    "    objective_fn: callable,\n",
    "    bounds: tuple,\n",
    "    num_dims: int,\n",
    "    num_particles: int,\n",
    "    max_iters: int,\n",
    "    c1: float,\n",
    "    c2: float,\n",
    "    w: float,\n",
    "    seed: random.PRNGKey,\n",
    "    eta: float,\n",
    "    steps: int,\n",
    ") -> tuple:\n",
    "    key = seed\n",
    "    lower, upper = jnp.array(bounds[0]), jnp.array(bounds[1])\n",
    "    k_pos, k_vel, k_state = random.split(key, 3)\n",
    "\n",
    "    search_range = upper - lower\n",
    "    velocity_scale = 0.1\n",
    "    limit = search_range * velocity_scale\n",
    "\n",
    "    init_positions = random.uniform(k_pos, (num_particles, num_dims), minval=lower, maxval=upper)\n",
    "    init_velocities = random.uniform(k_vel, (num_particles, num_dims), minval=-limit, maxval=limit)\n",
    "    init_fitness = vmap(objective_fn)(init_positions)\n",
    "\n",
    "    best_idx = jnp.argmin(init_fitness)\n",
    "    g_best_pos = init_positions[best_idx]\n",
    "    g_best_fit = init_fitness[best_idx]\n",
    "\n",
    "    initial_state = JaxGdSwarmState(\n",
    "        positions=init_positions,\n",
    "        velocities=init_velocities,\n",
    "        p_best_pos=init_positions,\n",
    "        p_best_fit=init_fitness,\n",
    "        g_best_pos=g_best_pos,\n",
    "        g_best_fit=g_best_fit,\n",
    "        rng=k_state,\n",
    "    )\n",
    "\n",
    "    gradient_fn = grad(objective_fn)\n",
    "\n",
    "    def update_step(swarm_state: JaxGdSwarmState, i: int) -> tuple:\n",
    "        k1, k2, k_next = random.split(swarm_state.rng, 3)\n",
    "        r1 = random.uniform(k1, (num_particles, num_dims))\n",
    "        r2 = random.uniform(k2, (num_particles, num_dims))\n",
    "\n",
    "        inertia = w * swarm_state.velocities\n",
    "        cognitive = c1 * r1 * (swarm_state.p_best_pos - swarm_state.positions)\n",
    "        social = c2 * r2 * (swarm_state.g_best_pos - swarm_state.positions)\n",
    "\n",
    "        new_velocities = inertia + cognitive + social\n",
    "        new_positions = swarm_state.positions + new_velocities\n",
    "        new_positions = jnp.clip(new_positions, lower, upper)\n",
    "\n",
    "        new_fitness = vmap(objective_fn)(new_positions)\n",
    "\n",
    "        improved = new_fitness < swarm_state.p_best_fit\n",
    "\n",
    "        new_p_best_pos = jnp.where(improved[:, None], new_positions, swarm_state.p_best_pos)\n",
    "        new_p_best_fit = jnp.where(improved, new_fitness, swarm_state.p_best_fit)\n",
    "\n",
    "        current_g_best_idx = jnp.argmin(new_p_best_fit)\n",
    "        current_g_best_fit = new_p_best_fit[current_g_best_idx]\n",
    "\n",
    "        global_improved = current_g_best_fit < swarm_state.g_best_fit\n",
    "\n",
    "        candidate_g_pos = jnp.where(\n",
    "            global_improved,\n",
    "            new_p_best_pos[current_g_best_idx],\n",
    "            swarm_state.g_best_pos,\n",
    "        )\n",
    "\n",
    "        candidate_g_fit = jnp.where(global_improved, current_g_best_fit, swarm_state.g_best_fit)\n",
    "\n",
    "        def gradient_descent_step(g_state: GradientState, _: None) -> tuple:\n",
    "            grads = gradient_fn(g_state.current_pos)\n",
    "            updated_pos = g_state.current_pos - eta * grads\n",
    "            updated_pos = jnp.clip(updated_pos, lower, upper)\n",
    "            return GradientState(updated_pos), None\n",
    "\n",
    "        def apply_gradient(_: None) -> tuple:\n",
    "            init_grad_state = GradientState(candidate_g_pos)\n",
    "            final_grad_state, _ = lax.scan(\n",
    "                gradient_descent_step,\n",
    "                init_grad_state,\n",
    "                None,\n",
    "                steps,\n",
    "            )\n",
    "            final_pos = final_grad_state.current_pos\n",
    "            final_fit = objective_fn(final_pos)\n",
    "            return final_pos, final_fit\n",
    "\n",
    "        def skip_gradient(_: None) -> tuple:\n",
    "            return candidate_g_pos, candidate_g_fit\n",
    "\n",
    "        gradient_g_pos, gradient_g_fit = lax.cond(\n",
    "            i % 10 == 0,\n",
    "            apply_gradient,\n",
    "            skip_gradient,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "        gd_improved = gradient_g_fit < candidate_g_fit\n",
    "        final_g_pos = jnp.where(gd_improved, gradient_g_pos, candidate_g_pos)\n",
    "        final_g_fit = jnp.where(gd_improved, gradient_g_fit, candidate_g_fit)\n",
    "\n",
    "        any_improvement = final_g_fit < swarm_state.g_best_fit\n",
    "\n",
    "        target_idx = current_g_best_idx\n",
    "\n",
    "        mask_winner = (jnp.arange(num_particles) == target_idx)[:, None]\n",
    "        should_update_mask = (gd_improved & any_improvement) & mask_winner\n",
    "\n",
    "        final_p_best_pos = jnp.where(\n",
    "            should_update_mask,\n",
    "            final_g_pos,\n",
    "            new_p_best_pos,\n",
    "        )\n",
    "\n",
    "        final_p_best_fit = jnp.where(\n",
    "            (gd_improved & any_improvement) & (jnp.arange(num_particles) == target_idx),\n",
    "            final_g_fit,\n",
    "            new_p_best_fit,\n",
    "        )\n",
    "\n",
    "        next_state = JaxGdSwarmState(\n",
    "            positions=new_positions,\n",
    "            velocities=new_velocities,\n",
    "            p_best_pos=final_p_best_pos,\n",
    "            p_best_fit=final_p_best_fit,\n",
    "            g_best_pos=final_g_pos,\n",
    "            g_best_fit=final_g_fit,\n",
    "            rng=k_next,\n",
    "        )\n",
    "\n",
    "        return next_state, final_g_fit\n",
    "\n",
    "    final_state, history = lax.scan(update_step, initial_state, jnp.arange(max_iters))\n",
    "    full_history = jnp.concatenate([jnp.array([initial_state.g_best_fit]), history])\n",
    "\n",
    "    return final_state.g_best_pos, final_state.g_best_fit, full_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7356ef",
   "metadata": {},
   "source": [
    "# pso.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwarmState(NamedTuple):\n",
    "    positions: np.ndarray\n",
    "    velocities: np.ndarray\n",
    "    p_best_pos: np.ndarray\n",
    "    p_best_fit: np.ndarray\n",
    "    g_best_pos: np.ndarray\n",
    "    g_best_fit: np.ndarray\n",
    "    rng: np.random.Generator\n",
    "    history: np.ndarray\n",
    "\n",
    "\n",
    "def pso(\n",
    "    objective_fn: callable,\n",
    "    bounds: tuple,\n",
    "    num_dims: int,\n",
    "    num_particles: int,\n",
    "    max_iters: int,\n",
    "    c1: float,\n",
    "    c2: float,\n",
    "    w: float,\n",
    "    seed: int,\n",
    "    **_: any,\n",
    ") -> tuple:\n",
    "    lower, upper = bounds\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    init_positions = rng.uniform(lower, upper, (num_particles, num_dims))\n",
    "    init_velocities = np.zeros((num_particles, num_dims))\n",
    "    init_fitness = np.array([objective_fn(position) for position in init_positions])\n",
    "\n",
    "    best_idx = np.argmin(init_fitness)\n",
    "    g_best_pos = init_positions[best_idx]\n",
    "    g_best_fit = init_fitness[best_idx]\n",
    "\n",
    "    history = np.zeros(max_iters)\n",
    "    history[0] = g_best_fit\n",
    "\n",
    "    swarm_state = SwarmState(\n",
    "        positions=init_positions,\n",
    "        velocities=init_velocities,\n",
    "        p_best_pos=init_positions,\n",
    "        p_best_fit=init_fitness,\n",
    "        g_best_pos=g_best_pos,\n",
    "        g_best_fit=g_best_fit,\n",
    "        rng=rng,\n",
    "        history=history,\n",
    "    )\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        r1 = swarm_state.rng.random((num_particles, num_dims))\n",
    "        r2 = swarm_state.rng.random((num_particles, num_dims))\n",
    "\n",
    "        inertia = w * swarm_state.velocities\n",
    "        cognitive = c1 * r1 * (swarm_state.p_best_pos - swarm_state.positions)\n",
    "        social = c2 * r2 * (swarm_state.g_best_pos - swarm_state.positions)\n",
    "\n",
    "        new_velocities = inertia + cognitive + social\n",
    "        new_positions = swarm_state.positions + new_velocities\n",
    "        new_positions = np.clip(new_positions, lower, upper)\n",
    "\n",
    "        new_fitness = np.array([objective_fn(pos) for pos in new_positions])\n",
    "\n",
    "        improved = new_fitness < swarm_state.p_best_fit\n",
    "        mask = improved[:, None]\n",
    "        new_p_best_pos = np.where(mask, new_positions, swarm_state.p_best_pos)\n",
    "        new_p_best_fit = np.where(improved, new_fitness, swarm_state.p_best_fit)\n",
    "\n",
    "        current_g_best_idx = np.argmin(new_p_best_fit)\n",
    "        current_g_best_fit = new_p_best_fit[current_g_best_idx]\n",
    "        global_improved = current_g_best_fit < swarm_state.g_best_fit\n",
    "        new_g_best_pos = np.where(\n",
    "            global_improved,\n",
    "            new_p_best_pos[current_g_best_idx],\n",
    "            swarm_state.g_best_pos,\n",
    "        )\n",
    "        new_g_best_fit = np.where(\n",
    "            global_improved,\n",
    "            current_g_best_fit,\n",
    "            swarm_state.g_best_fit,\n",
    "        )\n",
    "\n",
    "        new_history = swarm_state.history\n",
    "        new_history[i] = new_g_best_fit\n",
    "\n",
    "        swarm_state = SwarmState(\n",
    "            positions=new_positions,\n",
    "            velocities=new_velocities,\n",
    "            p_best_pos=new_p_best_pos,\n",
    "            p_best_fit=new_p_best_fit,\n",
    "            g_best_pos=new_g_best_pos,\n",
    "            g_best_fit=new_g_best_fit,\n",
    "            rng=swarm_state.rng,\n",
    "            history=new_history,\n",
    "        )\n",
    "\n",
    "    return swarm_state.g_best_pos, swarm_state.g_best_fit, swarm_state.history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33198d1",
   "metadata": {},
   "source": [
    "# plot_benchmarks.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e98c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_figure(fig: plt.Figure, filename: str, config: dict) -> None:\n",
    "    save_path = config[\"output_path\"] / filename\n",
    "    fig.savefig(save_path, bbox_inches=\"tight\", format=\"pdf\", dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_execution_time(df: pd.DataFrame, config: dict) -> None:\n",
    "    benchmarks = df[\"Benchmark\"].unique()\n",
    "    algorithms = df[\"Algorithm\"].unique()\n",
    "    dimensions = df[\"Dimension\"].unique()\n",
    "    colors = sns.color_palette(config[\"palette\"], n_colors=len(algorithms))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "    axes_flattened = axes.flatten()\n",
    "\n",
    "    for ax, benchmark in zip(axes_flattened, benchmarks):\n",
    "        df_benchmark = df[df[\"Benchmark\"] == benchmark]\n",
    "\n",
    "        for idx, algorithm in enumerate(algorithms):\n",
    "            df_subset = df_benchmark[df_benchmark[\"Algorithm\"] == algorithm]\n",
    "            mean = df_subset[\"Mean of Execution Times (s)\"]\n",
    "            std = df_subset[\"Standard Deviation of Execution Times (s)\"]\n",
    "\n",
    "            ax.plot(dimensions, mean, marker=\"o\", label=algorithm, color=colors[idx])\n",
    "            ax.fill_between(dimensions, mean - std, mean + std, color=colors[idx], alpha=0.2)\n",
    "\n",
    "        ax.set_xlabel(\"Dimension\")\n",
    "        ax.set_ylabel(\"Time (s)\")\n",
    "        ax.set_title(f\"{benchmark}\", fontweight=\"bold\")\n",
    "\n",
    "        if ax == axes_flattened[0]:\n",
    "            ax.legend(title=\"Algorithm\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    _save_figure(fig, \"execution_time_plot.pdf\", config)\n",
    "\n",
    "\n",
    "def plot_convergence(df: pd.DataFrame, config: dict) -> None:\n",
    "    benchmarks = df[\"Benchmark\"].unique()\n",
    "    dimensions = df[\"Dimension\"].unique()\n",
    "    algorithms = df[\"Algorithm\"].unique()\n",
    "    colors = sns.color_palette(config[\"palette\"], n_colors=len(algorithms))\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "\n",
    "    for i, benchmark in enumerate(benchmarks):\n",
    "        for j, dimension in enumerate(dimensions):\n",
    "            ax = axes[i, j]\n",
    "            df_subset = df[(df[\"Dimension\"] == dimension) & (df[\"Benchmark\"] == benchmark)]\n",
    "\n",
    "            for k, (_, row) in enumerate(df_subset.iterrows()):\n",
    "                mean_history = jnp.array(row[\"Mean Fitness History\"])\n",
    "                std_history = jnp.array(row[\"Std Fitness History\"])\n",
    "                iterations = range(len(mean_history))\n",
    "\n",
    "                ax.plot(iterations, mean_history, label=row[\"Algorithm\"], color=colors[k])\n",
    "                ax.fill_between(\n",
    "                    iterations,\n",
    "                    mean_history - std_history,\n",
    "                    mean_history + std_history,\n",
    "                    alpha=0.2,\n",
    "                    color=colors[k],\n",
    "                )\n",
    "\n",
    "            ax.set_xlabel(\"Iteration\")\n",
    "            ax.set_ylabel(\"Fitness\")\n",
    "            ax.set_title(f\"{benchmark} - {dimension}D\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    _save_figure(fig, \"convergence_plot.pdf\", config)\n",
    "\n",
    "\n",
    "def _generate_comparison_table(\n",
    "    df: pd.DataFrame,\n",
    "    config: dict,\n",
    "    mean_col: str,\n",
    "    std_col: str,\n",
    "    output_filename: str,\n",
    "    caption: str,\n",
    "    label: str,\n",
    ") -> None:\n",
    "    df_proc = df.copy()\n",
    "\n",
    "    df_proc[\"formatted\"] = (\n",
    "        df_proc[mean_col].map(\"{:.2e}\".format) + r\" $\\pm$ \" + df_proc[std_col].map(\"{:.2e}\".format)\n",
    "    )\n",
    "\n",
    "    df_pivot = df_proc.pivot_table(\n",
    "        index=[\"Benchmark\", \"Dimension\"],\n",
    "        columns=\"Algorithm\",\n",
    "        values=[\"formatted\", mean_col],\n",
    "        aggfunc=\"first\",\n",
    "    )\n",
    "\n",
    "    means = df_pivot[mean_col].fillna(float(\"inf\"))\n",
    "\n",
    "    display_df = df_pivot[\"formatted\"].copy()\n",
    "\n",
    "    for index, row in means.iterrows():\n",
    "        min_val = row.min()\n",
    "        is_min = row == min_val\n",
    "        for col in display_df.columns:\n",
    "            if is_min[col]:\n",
    "                display_df.loc[index, col] = f\"\\\\textbf{{{display_df.loc[index, col]}}}\"\n",
    "\n",
    "    display_df = display_df.reset_index()\n",
    "\n",
    "    output_path = config[\"output_path\"] / output_filename\n",
    "\n",
    "    latex_code = display_df.style.hide(axis=\"index\").to_latex(\n",
    "        column_format=\"llcc\",\n",
    "        hrules=True,\n",
    "        caption=caption,\n",
    "        label=label,\n",
    "        position=\"h\",\n",
    "    )\n",
    "\n",
    "    with output_path.open(\"w\") as f:\n",
    "        f.write(latex_code)\n",
    "\n",
    "\n",
    "def create_convergence_table(df: pd.DataFrame, config: dict) -> None:\n",
    "    _generate_comparison_table(\n",
    "        df=df,\n",
    "        config=config,\n",
    "        mean_col=\"Mean of Fitness\",\n",
    "        std_col=\"Standard Deviation of Fitness\",\n",
    "        output_filename=\"convergence_table.tex\",\n",
    "        caption=r\"Convergence comparison (Mean Fitness $\\pm$ Std Dev). Best results in bold.\",\n",
    "        label=\"tab:convergence\",\n",
    "    )\n",
    "\n",
    "\n",
    "def create_execution_time_table(df: pd.DataFrame, config: dict) -> None:\n",
    "    _generate_comparison_table(\n",
    "        df=df,\n",
    "        config=config,\n",
    "        mean_col=\"Mean of Execution Times (s)\",\n",
    "        std_col=\"Standard Deviation of Execution Times (s)\",\n",
    "        output_filename=\"execution_time_table.tex\",\n",
    "        caption=\"Execution time comparison in seconds.\",\n",
    "        label=\"tab:execution_time\",\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_visualizations(df: pd.DataFrame, config: dict) -> None:\n",
    "    print(\"Plotting convergence...\")\n",
    "    plot_convergence(df, config)\n",
    "\n",
    "    print(\"Plotting execution time...\")\n",
    "    plot_execution_time(df, config)\n",
    "\n",
    "    print(\"Creating convergence table (LaTeX)...\")\n",
    "    create_convergence_table(df, config)\n",
    "\n",
    "    print(\"Creating execution time table (LaTeX)...\")\n",
    "    create_execution_time_table(df, config)\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"output_path\": Path(\"./results/\"),\n",
    "    \"palette\": \"viridis\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6573d381",
   "metadata": {},
   "source": [
    "# benchmarks.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5015030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ackley_np(x: np.ndarray) -> float:\n",
    "    n = x.shape[0]\n",
    "    sum1 = np.sum(x**2)\n",
    "    sum2 = np.sum(np.cos(2 * np.pi * x))\n",
    "    return -20 * np.exp(-0.2 * np.sqrt(sum1 / n)) - np.exp(sum2 / n) + 20 + np.e\n",
    "\n",
    "\n",
    "def rastrigin_np(x: np.ndarray) -> float:\n",
    "    n = x.shape[0]\n",
    "    return 10 * n + np.sum(x**2 - 10 * np.cos(2 * np.pi * x))\n",
    "\n",
    "\n",
    "def sphere_np(x: np.ndarray) -> float:\n",
    "    return np.sum(x**2)\n",
    "\n",
    "\n",
    "def rosenbrock_np(x: np.ndarray) -> float:\n",
    "    return np.sum(100 * (x[1:] - x[:-1] ** 2) ** 2 + (1 - x[:-1]) ** 2)\n",
    "\n",
    "\n",
    "@jit\n",
    "def ackley_jax(x: jnp.ndarray) -> jnp.ndarray:\n",
    "    n = x.shape[0]\n",
    "    sum1 = jnp.sum(x**2)\n",
    "    sum2 = jnp.sum(jnp.cos(2 * jnp.pi * x))\n",
    "    return -20 * jnp.exp(-0.2 * jnp.sqrt(sum1 / n)) - jnp.exp(sum2 / n) + 20 + jnp.e\n",
    "\n",
    "\n",
    "@jit\n",
    "def rastrigin_jax(x: jnp.ndarray) -> jnp.ndarray:\n",
    "    n = x.shape[0]\n",
    "    return 10 * n + jnp.sum(x**2 - 10 * jnp.cos(2 * jnp.pi * x))\n",
    "\n",
    "\n",
    "@jit\n",
    "def sphere_jax(x: jnp.ndarray) -> jnp.ndarray:\n",
    "    return jnp.sum(x**2)\n",
    "\n",
    "\n",
    "@jit\n",
    "def rosenbrock_jax(x: jnp.ndarray) -> jnp.ndarray:\n",
    "    return jnp.sum(100 * (x[1:] - x[:-1] ** 2) ** 2 + (1 - x[:-1]) ** 2)\n",
    "\n",
    "\n",
    "BENCHMARKS = {\n",
    "    \"Ackley\": {\n",
    "        \"bounds\": (-32.768, 32.768),\n",
    "        \"PSO\": ackley_np,\n",
    "        \"JAX-GD-PSO\": ackley_jax,\n",
    "    },\n",
    "    \"Rastrigin\": {\n",
    "        \"bounds\": (-5.12, 5.12),\n",
    "        \"PSO\": rastrigin_np,\n",
    "        \"JAX-GD-PSO\": rastrigin_jax,\n",
    "    },\n",
    "    \"Rosenbrock\": {\n",
    "        \"bounds\": (-5.0, 10.0),\n",
    "        \"PSO\": rosenbrock_np,\n",
    "        \"JAX-GD-PSO\": rosenbrock_jax,\n",
    "    },\n",
    "    \"Sphere\": {\n",
    "        \"bounds\": (-5.12, 5.12),\n",
    "        \"PSO\": sphere_np,\n",
    "        \"JAX-GD-PSO\": sphere_jax,\n",
    "    },\n",
    "}\n",
    "\n",
    "ALGORITHMS = {\n",
    "    \"PSO\": pso,\n",
    "    \"JAX-GD-PSO\": jax_gd_pso,\n",
    "}\n",
    "\n",
    "DIMS = [30, 100, 500, 1000]\n",
    "\n",
    "HYPERPARAMETERS = {\n",
    "    \"num_dims\": None,\n",
    "    \"num_particles\": 30,\n",
    "    \"max_iters\": 1000,\n",
    "    \"c1\": 1.5,\n",
    "    \"c2\": 1.5,\n",
    "    \"w\": 0.7,\n",
    "    \"seed\": None,\n",
    "    \"eta\": 0.01,\n",
    "    \"steps\": 5,\n",
    "}\n",
    "\n",
    "NUM_RUNS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90b675",
   "metadata": {},
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment() -> list[dict]:\n",
    "    results = []\n",
    "\n",
    "    total_configs = len(DIMS) * len(ALGORITHMS) * len(BENCHMARKS)\n",
    "    current_config = 0\n",
    "\n",
    "    for dim in DIMS:\n",
    "        print(f\"Dimension: {dim}\")\n",
    "        for algorithm_name, algorithm_fn in ALGORITHMS.items():\n",
    "            for benchmark_name, benchmark_config in BENCHMARKS.items():\n",
    "                current_config += 1\n",
    "\n",
    "                objective_fn = benchmark_config[algorithm_name]\n",
    "                bounds = benchmark_config[\"bounds\"]\n",
    "                hyperparameters = HYPERPARAMETERS.copy()\n",
    "                hyperparameters[\"num_dims\"] = dim\n",
    "\n",
    "                print(\n",
    "                    f\"[{current_config}/{total_configs}] Running {algorithm_name} \"\n",
    "                    f\"on {benchmark_name}\",\n",
    "                )\n",
    "\n",
    "                execution_times = []\n",
    "                fitness_history = []\n",
    "                for i in range(NUM_RUNS):\n",
    "                    hyperparameters[\"seed\"] = i\n",
    "\n",
    "                    if algorithm_name == \"JAX-GD-PSO\":\n",
    "                        hyperparameters[\"seed\"] = random.PRNGKey(i)\n",
    "                        algorithm_fn(objective_fn, bounds, **hyperparameters)\n",
    "\n",
    "                    start = time.perf_counter()\n",
    "                    result = algorithm_fn(objective_fn, bounds, **hyperparameters)\n",
    "\n",
    "                    if algorithm_name == \"JAX-GD-PSO\":\n",
    "                        block_until_ready(result)\n",
    "\n",
    "                    end = time.perf_counter()\n",
    "                    execution_times.append(end - start)\n",
    "\n",
    "                    _, fitness, history = result\n",
    "\n",
    "                    print(f\"Iteration {i + 1} | Fitness: {fitness}\")\n",
    "                    fitness_history.append(history)\n",
    "\n",
    "                mean_fitness_history = jnp.mean(jnp.array(fitness_history), axis=0)\n",
    "                std_fitness_history = jnp.std(jnp.array(fitness_history), axis=0)\n",
    "\n",
    "                mean_time = float(jnp.mean(jnp.array(execution_times)))\n",
    "                std_time = float(jnp.std(jnp.array(execution_times)))\n",
    "\n",
    "                mean_fitness = float(jnp.mean(mean_fitness_history))\n",
    "                std_fitness = float(jnp.std(std_fitness_history))\n",
    "\n",
    "                results.extend(\n",
    "                    [\n",
    "                        {\n",
    "                            \"Dimension\": dim,\n",
    "                            \"Benchmark\": benchmark_name,\n",
    "                            \"Algorithm\": algorithm_name,\n",
    "                            \"Execution Time History\": execution_times,\n",
    "                            \"Mean of Execution Times (s)\": mean_time,\n",
    "                            \"Standard Deviation of Execution Times (s)\": std_time,\n",
    "                            \"Mean Fitness History\": mean_fitness_history.tolist(),\n",
    "                            \"Std Fitness History\": std_fitness_history.tolist(),\n",
    "                            \"Mean of Fitness\": mean_fitness,\n",
    "                            \"Standard Deviation of Fitness\": std_fitness,\n",
    "                        },\n",
    "                    ],\n",
    "                )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_experiment()\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce57a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./experiment_results.csv\")\n",
    "generate_visualizations(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
